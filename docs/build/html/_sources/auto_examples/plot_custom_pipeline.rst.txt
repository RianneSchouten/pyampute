
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_custom_pipeline.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_custom_pipeline.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_custom_pipeline.py:


=========================================
A custom pipeline with more possibilities
=========================================

Earlier, we demonstrated how :class:`~pyampute.ampute.MultivariateAmputation` can be integrated in a scikit-learn pipeline (see `A quick example`_ and `Evaluating missing values with grid search and a pipeline`_).

It may be valuable to understand the impact of missing values in more detail. Therefore, we demonstrate how a ``CustomTransformer`` and ``CustomEstimator`` can be used to do a more thorough analysis. Not only will such analysis gain insights in the statistical problems of missing data (and some imputation methods), but it will also help you to create real-world and realistic missingness scenarios.

Another example, of a more systematic approach, can be found in `Schouten and Vink (2021)`_.

.. _`A quick example`: https://rianneschouten.github.io/pyampute/build/html/auto_examples/plot_easy_example.html
.. _`Evaluating missing values with grid search and a pipeline`: https://rianneschouten.github.io/pyampute/build/html/auto_examples/plot_simulation_pipeline.html
.. _`Schouten and Vink (2021)`: https://journals.sagepub.com/doi/full/10.1177/0049124118799376

.. GENERATED FROM PYTHON SOURCE LINES 17-20

.. code-block:: default


    # Author: Rianne Schouten <https://rianneschouten.github.io/>








.. GENERATED FROM PYTHON SOURCE LINES 21-27

Recap
######

 Given is the following setting (from `Evaluating missing values with grid search and a pipeline`_):

 .. _`Evaluating missing values with grid search and a pipeline`: https://rianneschouten.github.io/pyampute/build/html/auto_examples/plot_simulation_pipeline.html

.. GENERATED FROM PYTHON SOURCE LINES 27-40

.. code-block:: default


    import numpy as np

    m = 5
    n = 10000

    mean = np.repeat(5, m)
    cor = 0.5
    cov = np.identity(m)
    cov[cov == 0] = cor
    rng = np.random.default_rng()
    compl_dataset = rng.multivariate_normal(mean, cov, n)








.. GENERATED FROM PYTHON SOURCE LINES 41-43

As amputation parameter settings, we will vary the proportion, the mechanism and the ``score_to_probability_func``. Since in  the latter have to be specified within the same dictionary, we define the parameters for the grid search as follows.


.. GENERATED FROM PYTHON SOURCE LINES 43-56

.. code-block:: default


    import itertools as it

    mechs = ["MCAR", "MAR", "MNAR"]
    funcs = ["sigmoid-right", "sigmoid-mid"]

    parameters = {
        "amputation__prop": [0.1, 0.5, 0.9],
        "amputation__patterns": [
            [{"incomplete_vars": [0,1], "mechanism": mechanism, "score_to_probability_func": func}]
            for mechanism, func in list(it.product(mechs, funcs))]
    }








.. GENERATED FROM PYTHON SOURCE LINES 57-62

A transformer that drops incomplete rows
#########################################

 Previously, we evaluated the ``SimpleImputer`` class from scikit-learn. Another good way to evaluate the effect of missing values, is by analyzing the incomplete dataset directly. Since most prediction and analysis models do not accept missing values, we apply the `dropna` or `listwise deletion` or `complete case analysis` method (all names refer to the same strategy). To allow for integration in a pipeline, we set up a custom ``TransformerMixin``.


.. GENERATED FROM PYTHON SOURCE LINES 62-83

.. code-block:: default


    from sklearn.base import TransformerMixin

    class DropTransformer(TransformerMixin):

        def __init__(self):
            super().__init__()

        def fit(self, X, y=None):
            self.X = X
        
            return self

        def transform(self, X, y=None):

            # drop incomplete rows
            Xp = pd.DataFrame(X)
            Xdrop = Xp.dropna().to_numpy()
		
            return Xdrop








.. GENERATED FROM PYTHON SOURCE LINES 84-93

A custom estimator
###################

 Almost all, if not all, estimators and evaluation metrics in scikit-learn are aimed at prediction or classification. That is what most people want to do.

 However, for evaluating the effect of missing values on your model, it may be good to look further than just the prediction or classification accuracy. In this example, we will focus on the center of the distribution of one feature and evaluate the bias in that distribution.

 That could work as follows.


.. GENERATED FROM PYTHON SOURCE LINES 93-122

.. code-block:: default


    from sklearn.base import BaseEstimator 

    class CustomEstimator(BaseEstimator):

        def __init__(self):
            super().__init__()

        def fit(self, X, y=None):
            self.X = X
        
            return self

        def predict(self, X):

            # return values of first feature
            values_used_for_score = X[:,0]
		
            return values_used_for_score

    def my_evaluation_metric(y_true, y_pred):

        m1 = np.mean(y_true)
        m2 = np.mean(y_pred)

        bias = np.abs(m1 - m2)

        return bias








.. GENERATED FROM PYTHON SOURCE LINES 123-132

An evaluation pipeline
#######################

 As can be seen, the ``predict`` function returns the first feature of the transformed dataset. The evaluation metric then calculated the mean difference between that feature, and the truth.

 In our experiment, the complete dataset is the ground truth and we evaluate the impact of several missing data models (and imputation models) on that truth. 

 We then run the pipeline twice.


.. GENERATED FROM PYTHON SOURCE LINES 132-140

.. code-block:: default


    import pandas as pd
    from sklearn.pipeline import Pipeline
    from sklearn.model_selection import GridSearchCV
    from sklearn.impute import SimpleImputer
    from pyampute.ampute import MultivariateAmputation
    from sklearn.metrics import make_scorer








.. GENERATED FROM PYTHON SOURCE LINES 141-142

Once with the DropTransformer

.. GENERATED FROM PYTHON SOURCE LINES 142-155

.. code-block:: default


    steps = [('amputation', MultivariateAmputation()), ('imputation', DropTransformer()), ('estimator', CustomEstimator())]
    pipe = Pipeline(steps)
    grid = GridSearchCV(
        estimator=pipe,
        param_grid=parameters,
        scoring=make_scorer(my_evaluation_metric),
    )

    grid.fit(compl_dataset, np.zeros(len(compl_dataset)))
    grid.score(compl_dataset, compl_dataset[:,0])
    results_drop = pd.DataFrame(grid.cv_results_)








.. GENERATED FROM PYTHON SOURCE LINES 156-157

Once with the SimpleImputer

.. GENERATED FROM PYTHON SOURCE LINES 157-170

.. code-block:: default


    steps = [('amputation', MultivariateAmputation()), ('imputation', SimpleImputer()), ('estimator', CustomEstimator())]
    pipe = Pipeline(steps)
    grid = GridSearchCV(
        estimator=pipe,
        param_grid=parameters,
        scoring=make_scorer(my_evaluation_metric),
    )

    grid.fit(compl_dataset, np.zeros(len(compl_dataset)))
    grid.score(compl_dataset, compl_dataset[:,0])
    results_mean = pd.DataFrame(grid.cv_results_)








.. GENERATED FROM PYTHON SOURCE LINES 171-174

Comparison
###########


.. GENERATED FROM PYTHON SOURCE LINES 174-183

.. code-block:: default


    res_drop = results_drop[['param_amputation__patterns', 'param_amputation__prop', 'mean_test_score']]
    res_mean = results_mean[['param_amputation__patterns', 'param_amputation__prop', 'mean_test_score']]

    res_drop.columns = ['mechanism, func', 'prop', 'score']
    res_mean.columns = ['mechanism, func', 'prop', 'score']

    res_drop






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>mechanism, func</th>
          <th>prop</th>
          <th>score</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.1</td>
          <td>4.998796</td>
        </tr>
        <tr>
          <th>1</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.5</td>
          <td>4.998061</td>
        </tr>
        <tr>
          <th>2</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.9</td>
          <td>4.993133</td>
        </tr>
        <tr>
          <th>3</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.1</td>
          <td>5.005670</td>
        </tr>
        <tr>
          <th>4</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.5</td>
          <td>5.010373</td>
        </tr>
        <tr>
          <th>5</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.9</td>
          <td>5.024687</td>
        </tr>
        <tr>
          <th>6</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.1</td>
          <td>4.945268</td>
        </tr>
        <tr>
          <th>7</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.5</td>
          <td>4.748383</td>
        </tr>
        <tr>
          <th>8</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.9</td>
          <td>4.510414</td>
        </tr>
        <tr>
          <th>9</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.1</td>
          <td>4.998428</td>
        </tr>
        <tr>
          <th>10</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.5</td>
          <td>5.014696</td>
        </tr>
        <tr>
          <th>11</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.9</td>
          <td>4.972411</td>
        </tr>
        <tr>
          <th>12</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.1</td>
          <td>4.917843</td>
        </tr>
        <tr>
          <th>13</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.5</td>
          <td>4.636337</td>
        </tr>
        <tr>
          <th>14</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.9</td>
          <td>4.312762</td>
        </tr>
        <tr>
          <th>15</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.1</td>
          <td>4.993687</td>
        </tr>
        <tr>
          <th>16</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.5</td>
          <td>4.999428</td>
        </tr>
        <tr>
          <th>17</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.9</td>
          <td>4.970546</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 184-187

.. code-block:: default


    res_mean






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>mechanism, func</th>
          <th>prop</th>
          <th>score</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.1</td>
          <td>4.999176</td>
        </tr>
        <tr>
          <th>1</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.5</td>
          <td>5.003938</td>
        </tr>
        <tr>
          <th>2</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.9</td>
          <td>4.991379</td>
        </tr>
        <tr>
          <th>3</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.1</td>
          <td>5.002979</td>
        </tr>
        <tr>
          <th>4</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.5</td>
          <td>4.999179</td>
        </tr>
        <tr>
          <th>5</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MCA...</td>
          <td>0.9</td>
          <td>5.013873</td>
        </tr>
        <tr>
          <th>6</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.1</td>
          <td>4.944237</td>
        </tr>
        <tr>
          <th>7</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.5</td>
          <td>4.749489</td>
        </tr>
        <tr>
          <th>8</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.9</td>
          <td>4.520981</td>
        </tr>
        <tr>
          <th>9</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.1</td>
          <td>4.996579</td>
        </tr>
        <tr>
          <th>10</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.5</td>
          <td>5.004579</td>
        </tr>
        <tr>
          <th>11</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MAR...</td>
          <td>0.9</td>
          <td>5.010057</td>
        </tr>
        <tr>
          <th>12</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.1</td>
          <td>4.916333</td>
        </tr>
        <tr>
          <th>13</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.5</td>
          <td>4.639330</td>
        </tr>
        <tr>
          <th>14</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.9</td>
          <td>4.310698</td>
        </tr>
        <tr>
          <th>15</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.1</td>
          <td>4.999446</td>
        </tr>
        <tr>
          <th>16</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.5</td>
          <td>4.992550</td>
        </tr>
        <tr>
          <th>17</th>
          <td>[{'incomplete_vars': [0, 1], 'mechanism': 'MNA...</td>
          <td>0.9</td>
          <td>5.023169</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 188-199

What you find here, is that a MCAR mechanism will not affect the center of the distribution of the first feature much, independent of the proportion of incomplete rows. 

A MAR mechanism with a sigmoid-right probability function will, on average, remove the right-hand side of the distribution (also, because there is a positive correlation between the observed data and the first feature). Therefore, the larger the proportion, the more bias. However, with a sigmoid-mid probability function, values in the center of the distribution of the first feature are removed, and there is therefore not much effect on the bias. 

The same logic applies to MNAR missingness, but since MNAR missingness does not depend on the size of the correlation between observed data and incomplete data, the bias will be stronger.

`Schouten and Vink (2021)`_ further discuss this topic and the effect of multiple imputation (which can be performed using scikit-learn's IterativeImputer).

SimpleImputer will use the mean of the observed data in the first feature. Therefore, in case there is any bias, that bias will remain. In case there is no bias, mean imputation will distort the correlation structure with other features. But that is another story...

.. _`Schouten and Vink (2021)`: https://journals.sagepub.com/doi/full/10.1177/0049124118799376


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  6.931 seconds)


.. _sphx_glr_download_auto_examples_plot_custom_pipeline.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_custom_pipeline.py <plot_custom_pipeline.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_custom_pipeline.ipynb <plot_custom_pipeline.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
