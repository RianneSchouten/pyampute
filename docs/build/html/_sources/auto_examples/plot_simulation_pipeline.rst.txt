
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_simulation_pipeline.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_simulation_pipeline.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_simulation_pipeline.py:


====================================================
Evaluating missing values with a simulation pipeline
====================================================

Generating missing values in a complete dataset (we call this `amputation`) may seem like a bizarre thing to do. However, most people who work with all sorts of data will acknowledge that missing data is widespread and can be a severe issue for various types of analyses and models. In order to understand the effect of missing values and to know which missing data methods are appropriate in which situation, we perform simulation studies. And for that, we need amputation. 

With package ``pyampute``, we provide the multivariate amputation methodology proposed by `Schouten et al. (2018)`_. Because our :class:`~pyampute.ampute.MultivariateAmputation` class is built on an sklearn TransformerMixin, it is easy to integrate such evaluation in a larger experiment. Here, we will demonstrate how that works. 

.. _`Schouten et al. (2018)`: https://www.tandfonline.com/doi/full/10.1080/00949655.2018.1491577

.. GENERATED FROM PYTHON SOURCE LINES 12-15

.. code-block:: default


    # Author: Rianne Schouten <https://rianneschouten.github.io/>








.. GENERATED FROM PYTHON SOURCE LINES 16-28

General experimental setup
###########################

 In general, evaluating the effect of missing values is done in four steps:

 1. Generate or import a complete dataset
 2. Ampute the dataset
 3. Impute the dataset
 4. Compare the performance of a model between the datasets in step 1, 2 and 3. 

 It is often wise to first inspect the effect of amputation (by comparing the datasets in steps 1 and 2) before comparing with the dataset in step 3. Let's get started.


.. GENERATED FROM PYTHON SOURCE LINES 30-36

Complete datasets
##################

 A simulation starts with a complete dataset. Make sure that you use a dataset where variables are correlated with each other; otherwise it will not make sense to use weights in a MAR or MNAR mechanism (see `Schouten et al. (2021)`_ for a discussion on this topic). 

 .. `Schouten et al. (2021)`: https://journals.sagepub.com/doi/full/10.1177/0049124118799376

.. GENERATED FROM PYTHON SOURCE LINES 36-48

.. code-block:: default


    import numpy as np

    m = 3
    n = 1000

    mean = np.repeat(5,m)
    cor = 0.5
    cov = np.identity(m)
    cov[cov == 0] = cor
    compl_dataset = np.random.multivariate_normal(mean, cov, n)








.. GENERATED FROM PYTHON SOURCE LINES 49-54

Multivariate amputation
########################

 Vary the parameters of the amputation procedure. As an example, we generate one missing data pattern with missing values in the first two variables. We vary the proportion of incomplete rows and the missingness mechanisms


.. GENERATED FROM PYTHON SOURCE LINES 54-57

.. code-block:: default


    parameters = {'amputation_prop': [0.1, 0.5, 0.9], 'amputation_patterns' : [{'incomplete_vars': [0,1], 'mechanism': "MCAR"}, {'incomplete_vars': [0,1], 'mechanism': "MAR"}, {'incomplete_vars': [0,1], 'mechanism': "MNAR"}]}








.. GENERATED FROM PYTHON SOURCE LINES 58-68

Missing data methods
#####################

 `SimpleImputer`_` is a univariate, single imputation method that is commonly used. However, in case of MCAR missingness, it distorts the relation with other variables, and in case of MAR and MNAR missingness it will not resolve issues with shifted variable distributions (see `Van Buuren (2018)`_) It may be better to use a method such as `IterativeImputer`_. 

 Yet, to demonstrate the working of a simulation pipeline, we will work with SimpleImputer for now.

 .. `SimpleImputer`: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html
 .. `Van Buuren (2018)`: https://stefvanbuuren.name/fimd/
 .. `IterativeImputer`: https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html

.. GENERATED FROM PYTHON SOURCE LINES 68-71

.. code-block:: default


    parameters['imputation_strategy'] = ["mean"]








.. GENERATED FROM PYTHON SOURCE LINES 72-81

Evaluation
###########

 How you wish to evaluate the appropriateness of a missing data method greatly depends on the goal of your model. When you develop a prediction or classification model, you may want to use a standard estimator and evaluation metric.

 Here, as an example, we evaluate using principles from statistical theory, where the goal is to find an unbiased and efficient estimate of a population parameter in a sample (that contains missing values). As an easy example, we evaluate an estimate of the mean of a variable, in this case the mean of the first variable. 

 Therefore, we set up an empty BaseEstimator that returns the values of the first variable. We then design a custom evaluation metric. Since we work with one complete dataset, the true population estimate is the mean of the variable in that dataset. Note, in case we would repeatedly sample a complete dataset, the values of the distribution would become the true population estimate. Here, that would be ``true_mean = 5``.


.. GENERATED FROM PYTHON SOURCE LINES 81-105

.. code-block:: default


    from sklearn.base import BaseEstimator

    class CustomEstimator(BaseEstimator):

        def __init__(self):
            super().__init__()

        def fit(self, X):
            self.X = X
        
            return self

        def predict(self, X):
            values_first_variable = X[:,0]
		
            return values_first_variable

    def my_evaluation_metric(y_true, y_pred):

        bias = np.abs(np.mean(y_true) - np.mean(y_pred))

        return bias








.. GENERATED FROM PYTHON SOURCE LINES 106-111

Altogether
###########

 We then create our pipeline, and run an exhaustive grid search to see the effect of various parameters on the bias of the mean of the first variable.


.. GENERATED FROM PYTHON SOURCE LINES 111-125

.. code-block:: default


    import pandas as pd
    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.model_selection import GridSearchCV
    from pyampute.ampute import MultivariateAmputation

    steps = [('amputation', MultivariateAmputation()), ('imputation', SimpleImputer()), ('estimator', CustomEstimator())]
    pipe = Pipeline(steps)
    grid = GridSearchCV(estimator=pipe, param_grid=parameters, scoring=my_evaluation_metric)

    grid.fit(compl_dataset)
    grid.score(compl_dataset, compl_dataset[:,0])
    pd.DataFrame(grid.cv_results_)


.. rst-class:: sphx-glr-script-out

.. code-block:: pytb

    Traceback (most recent call last):
      File "/Users/davina/Documents/Stuff/Code/pyampute/examples/plot_simulation_pipeline.py", line 122, in <module>
        grid.fit(compl_dataset)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/sklearn/model_selection/_search.py", line 891, in fit
        self._run_search(evaluate_candidates)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/sklearn/model_selection/_search.py", line 1392, in _run_search
        evaluate_candidates(ParameterGrid(self.param_grid))
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/sklearn/model_selection/_search.py", line 838, in evaluate_candidates
        out = parallel(
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/joblib/parallel.py", line 1043, in __call__
        if self.dispatch_one_batch(iterator):
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/joblib/parallel.py", line 861, in dispatch_one_batch
        self._dispatch(tasks)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/joblib/parallel.py", line 779, in _dispatch
        job = self._backend.apply_async(batch, callback=cb)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 208, in apply_async
        result = ImmediateResult(func)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 572, in __init__
        self.results = batch()
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/joblib/parallel.py", line 262, in __call__
        return [func(*args, **kwargs)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/joblib/parallel.py", line 262, in <listcomp>
        return [func(*args, **kwargs)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/sklearn/utils/fixes.py", line 211, in __call__
        return self.function(*args, **kwargs)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 669, in _fit_and_score
        estimator = estimator.set_params(**cloned_parameters)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/sklearn/pipeline.py", line 188, in set_params
        self._set_params("steps", **kwargs)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 54, in _set_params
        super().set_params(**params)
      File "/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/sklearn/base.py", line 240, in set_params
        raise ValueError(
    ValueError: Invalid parameter amputation_patterns for estimator Pipeline(steps=[('amputation', MultivariateAmputation()),
                    ('imputation', SimpleImputer()),
                    ('estimator', CustomEstimator())]). Check the list of available parameters with `estimator.get_params().keys()`.





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.092 seconds)


.. _sphx_glr_download_auto_examples_plot_simulation_pipeline.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_simulation_pipeline.py <plot_simulation_pipeline.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_simulation_pipeline.ipynb <plot_simulation_pipeline.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
