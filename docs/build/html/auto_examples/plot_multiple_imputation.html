
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Single versus multiple imputation &#8212; pyampute 0.0.1 documentation</title>
    
    <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    
    <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../index.html">
<p class="title">pyampute</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pyampute.html">
  Package
  <code class="docutils literal notranslate">
   <span class="pre">
    pyampute
   </span>
  </code>
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../examples.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../blogposts.html">
  Blogposts
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../about.html">
  About us
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../contributing.html">
  Contribution Guidelines
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-plot-multiple-imputation-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="single-versus-multiple-imputation">
<span id="sphx-glr-auto-examples-plot-multiple-imputation-py"></span><h1>Single versus multiple imputation<a class="headerlink" href="#single-versus-multiple-imputation" title="Permalink to this headline">¶</a></h1>
<p>By default, the IterativeImputer performs single imputation: a method where
every missing value is replaced with one imputed value. The chained character
of the method and the possiblity to draw imputation values from the posterior
distribution of a Bayesian imputation model allows for the finding of unbiased
statistical estimates. However, the disadvantage is that every imputed value is
treated as if the value was observed, leading to an imputed dataset that does
not reflect the uncertainty that occurs due to the presence of missing values.
This makes it hard to find valid statistical inferences because the variance
(and standard error) of statistical estimates become too small.</p>
<p>An alternative is using the IterativeImputer to perform multiple imputation: a
method where every missing value is imputed multiple times. The procedure
results in multiple datasets where the observed data is similar in every
dataset, but the imputed data is different. All desired steps after imputation
are performed on every dataset, such as standardization and other feature
engineering steps. The estimation model is also fitted on each of the datasets.</p>
<p>One final model is obtained by combining the estimates of each model with
Rubin’s pooling rules. These rules assume that the parameters of interest are
normally distributed which is the case with, for example, estimates of the mean
and regression coefficients. Other parameters, such as correlation
coefficients need transformation to suit the assumption of normality.
If it is not possible to approximate a normal distribution, it is better to use
robust summary measures such as medians or ranges instead of using Rubin’s
pooling rules. This applies to an estimate like explained variance.</p>
<p>In sum, Rubin’s pooling rules are as follows. The overall point estimate after
multiple imputation (denoted by Qbar) is the average of all the m point
estimates. The variance of the overall point estimate is a combination of
so-called within imputation variance (Ubar) and between imputation
variance (B). Ubar is the average of the m variances of the m point estimates.
Both Qbar and Ubar are corrected with a factor 1 / m to account for sampling
variance. The between imputation variance (B) is the sum of the squared
difference between Qbar and the m point estimates, corrected with a factor
1 / (m – 1). Then, the total variance (T) of the MI overall point estimate is
Ubar + B + B/m.</p>
<p>In this document we will show how to use the IterativeImputer to perform
multiple imputation. In example 1 we show the effect of Rubin’s pooling
rules on the variance of regression estimates. Due to the between imputation
variance, the standard errors of all regression coefficients are larger with
multiple imputation than with single imputation. This allows for valid
statistical inference making.</p>
<p>In example 2 we show how to set up a prediction model using multiple
imputation. We compare two approaches. In one approach, we make predictions for
each of the m datasets and combine the m evaluation error metrics into one
overall value. In the other approach, we combine the predictions and calculate
one evaluation error metric over the averaged predictions. A short simulation
study shows that the second approach results in the smallest Mean Squared
Error.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">ChainedImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span> <span class="k">as</span> <span class="n">mse</span>

<span class="kn">from</span> <span class="nn">pyampute</span> <span class="kn">import</span> <span class="n">MultivariateAmputation</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Make a function that calculates the variance of the beta estimates. This is</span>
<span class="c1"># necessary because the linear regression model from sklearn does not provide</span>
<span class="c1"># these values.</span>
<span class="k">def</span> <span class="nf">calculate_variance_of_beta_estimates</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>

    <span class="n">residuals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">sigma_hat_squared</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="n">residuals</span>
    <span class="n">X_prime_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">sigma_hat_squared</span> <span class="o">/</span> <span class="n">X_prime_X</span>
    <span class="nb">vars</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">covariance_matrix</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">vars</span>


<span class="c1"># Apply Rubin&#39;s pooling rules as follows.</span>
<span class="c1"># The value of every estimate is the mean of the estimates in each of the m</span>
<span class="c1"># datasets (Qbar). The variance of these estimates is a combination of the</span>
<span class="c1"># variance of each of the m estimates (Ubar) and the variance between the m</span>
<span class="c1"># estimates (B).</span>
<span class="c1">#</span>
<span class="c1"># Make a function that calculates Qbar from m estimates</span>
<span class="k">def</span> <span class="nf">calculate_Qbar</span><span class="p">(</span><span class="n">m_estimates</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">m_estimates</span><span class="p">)</span>
    <span class="n">Qbar</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">m_estimates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Qbar</span>


<span class="c1"># Make a function that calculates T from m estimates and their variances</span>
<span class="k">def</span> <span class="nf">calculate_T</span><span class="p">(</span><span class="n">m_estimates</span><span class="p">,</span> <span class="n">m_variances</span><span class="p">,</span> <span class="n">Qbar</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">m_estimates</span><span class="p">)</span>
    <span class="n">Ubar</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">m_variances</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">Qbar</span> <span class="o">-</span> <span class="n">m_estimates</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">Ubar</span> <span class="o">+</span> <span class="n">B</span> <span class="o">+</span> <span class="p">(</span><span class="n">B</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">T</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-pytb notranslate"><div class="highlight"><pre><span></span><span class="gt">Traceback (most recent call last):</span>
  File <span class="nb">&quot;/Users/davina/Documents/Stuff/Code/pyampute/examples/plot_multiple_imputation.py&quot;</span>, line <span class="m">67</span>, in <span class="n">&lt;module&gt;</span>
    <span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">ChainedImputer</span>
<span class="gr">ImportError</span>: <span class="n">cannot import name &#39;ChainedImputer&#39; from &#39;sklearn.impute&#39; (/Users/davina/miniconda3/envs/pymice/lib/python3.9/site-packages/sklearn/impute/__init__.py)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># EXAMPLE 1. COMPARE STATISTICAL ESTIMATES AND THEIR VARIANCE USING MULTIPLE</span>
<span class="c1"># IMPUTATION IN A LINEAR REGRESSION MODEL.</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_results_full_dataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># Perform linear regression on full data as a way of comparison</span>
    <span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">y_predict</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># Save the beta estimates, the variance of these estimates and 1.96 *</span>
    <span class="c1"># standard error of the estimates. The latter is useful to know the 95%</span>
    <span class="c1"># confidence interval.</span>
    <span class="n">full_coefs</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span>
    <span class="n">full_vars</span> <span class="o">=</span> <span class="n">calculate_variance_of_beta_estimates</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">full_errorbar</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">full_vars</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">full_coefs</span><span class="p">,</span> <span class="n">full_vars</span><span class="p">,</span> <span class="n">full_errorbar</span>


<span class="k">def</span> <span class="nf">get_results_chained_imputation</span><span class="p">(</span><span class="n">X_incomplete</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># Impute incomplete data with IterativeImputer using single imputation</span>
    <span class="c1"># We set n_burn_in at 99 and use only the last imputation</span>
    <span class="n">imputer</span> <span class="o">=</span> <span class="n">ChainedImputer</span><span class="p">(</span><span class="n">n_burn_in</span><span class="o">=</span><span class="mi">99</span><span class="p">,</span> <span class="n">n_imputations</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_incomplete</span><span class="p">)</span>
    <span class="n">X_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_incomplete</span><span class="p">)</span>

    <span class="c1"># Perform linear regression on chained single imputed data</span>
    <span class="c1"># Estimate beta estimates and their variances</span>
    <span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_imputed</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">y_predict</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_imputed</span><span class="p">)</span>

    <span class="c1"># Save the beta estimates, the variance of these estimates and 1.96 *</span>
    <span class="c1"># standard error of the estimates</span>
    <span class="n">chained_coefs</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span>
    <span class="n">chained_vars</span> <span class="o">=</span> <span class="n">calculate_variance_of_beta_estimates</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">,</span> <span class="n">X_imputed</span><span class="p">)</span>
    <span class="n">chained_errorbar</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">chained_vars</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">chained_coefs</span><span class="p">,</span> <span class="n">chained_vars</span><span class="p">,</span> <span class="n">chained_errorbar</span>


<span class="k">def</span> <span class="nf">get_results_mice_imputation</span><span class="p">(</span><span class="n">X_incomplete</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># Impute incomplete data using the IterativeImputer to perform multiple</span>
    <span class="c1"># imputation. We set n_burn_in at 99 and use only last imputation and</span>
    <span class="c1"># loop this procedure m times.</span>
    <span class="n">m</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">multiple_imputations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">imputer</span> <span class="o">=</span> <span class="n">ChainedImputer</span><span class="p">(</span><span class="n">n_burn_in</span><span class="o">=</span><span class="mi">99</span><span class="p">,</span> <span class="n">n_imputations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
        <span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_incomplete</span><span class="p">)</span>
        <span class="n">X_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_incomplete</span><span class="p">)</span>
        <span class="n">multiple_imputations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_imputed</span><span class="p">)</span>

    <span class="c1"># Perform a model on each of the m imputed datasets</span>
    <span class="c1"># Estimate the estimates for each model/dataset</span>
    <span class="n">m_coefs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">m_vars</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">multiple_imputations</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">y_predict</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">multiple_imputations</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">m_coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
        <span class="n">m_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">calculate_variance_of_beta_estimates</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">,</span> <span class="n">multiple_imputations</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="p">)</span>

    <span class="c1"># Calculate the end estimates by applying Rubin&#39;s rules.</span>
    <span class="n">Qbar</span> <span class="o">=</span> <span class="n">calculate_Qbar</span><span class="p">(</span><span class="n">m_coefs</span><span class="p">)</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">calculate_T</span><span class="p">(</span><span class="n">m_coefs</span><span class="p">,</span> <span class="n">m_vars</span><span class="p">,</span> <span class="n">Qbar</span><span class="p">)</span>
    <span class="n">mice_errorbar</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Qbar</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mice_errorbar</span>


<span class="c1"># The original multiple imputation procedure as developed under the name</span>
<span class="c1"># MICE includes all variables in the imputation process; including the output</span>
<span class="c1"># variable. The reason to do this is that the imputation model should at least</span>
<span class="c1"># contain the analysis model to result in unbiased estimates. In this function,</span>
<span class="c1"># we will also include y in the imputation process.</span>
<span class="k">def</span> <span class="nf">get_results_mice_imputation_includingy</span><span class="p">(</span><span class="n">X_incomplete</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># Impute incomplete data using the IterativeImputer as a MICEImputer</span>
    <span class="c1"># Now using the output variable in the imputation loop</span>
    <span class="n">m</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">multiple_imputations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">Xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X_incomplete</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">imputer</span> <span class="o">=</span> <span class="n">ChainedImputer</span><span class="p">(</span><span class="n">n_burn_in</span><span class="o">=</span><span class="mi">99</span><span class="p">,</span> <span class="n">n_imputations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
        <span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xy</span><span class="p">)</span>
        <span class="n">data_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xy</span><span class="p">)</span>

        <span class="c1"># We save only the X imputed data because we do not want to use y to</span>
        <span class="c1"># predict y later on.</span>
        <span class="n">X_imputed</span> <span class="o">=</span> <span class="n">data_imputed</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">multiple_imputations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_imputed</span><span class="p">)</span>

    <span class="c1"># Perform linear regression on mice multiple imputed data</span>
    <span class="c1"># Estimate beta estimates and their variances</span>
    <span class="n">m_coefs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">m_vars</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">multiple_imputations</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">y_predict</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">multiple_imputations</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">m_coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
        <span class="n">m_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">calculate_variance_of_beta_estimates</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">,</span> <span class="n">multiple_imputations</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="p">)</span>

    <span class="c1"># Calculate the end estimates by applying Rubin&#39;s rules.</span>
    <span class="n">Qbar</span> <span class="o">=</span> <span class="n">calculate_Qbar</span><span class="p">(</span><span class="n">m_coefs</span><span class="p">)</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">calculate_T</span><span class="p">(</span><span class="n">m_coefs</span><span class="p">,</span> <span class="n">m_vars</span><span class="p">,</span> <span class="n">Qbar</span><span class="p">)</span>
    <span class="n">mice_errorbar</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Qbar</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mice_errorbar</span>


<span class="c1"># Now lets run all these imputation procedures.</span>
<span class="c1"># We use the Boston dataset and analyze the outcomes of the beta coefficients</span>
<span class="c1"># and their standard errors. We standardize the data before running the</span>
<span class="c1"># procedure to be able to compare the coefficients. We run the procedure for</span>
<span class="c1"># MCAR missingness only.</span>
<span class="c1">#</span>
<span class="c1"># Loading the data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">X_full</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># Standardizing the data</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span>
<span class="n">y_scaled</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">zscore</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Start the procedure</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Executing Example 1 MCAR Missingness...&quot;</span><span class="p">)</span>

<span class="c1"># First, make the data incomplete with a MCAR mechanism.</span>
<span class="n">am_MCAR</span> <span class="o">=</span> <span class="n">MultivariateAmputation</span><span class="p">(</span><span class="n">mechanisms</span><span class="o">=</span><span class="s2">&quot;MCAR&quot;</span><span class="p">)</span>
<span class="n">Boston_X_incomplete_MCAR</span> <span class="o">=</span> <span class="n">am_MCAR</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>

<span class="c1"># Second, run all the imputation procedures as described above.</span>
<span class="n">full_coefs</span><span class="p">,</span> <span class="n">full_vars</span><span class="p">,</span> <span class="n">full_errorbar</span> <span class="o">=</span> <span class="n">get_results_full_dataset</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y_scaled</span><span class="p">)</span>
<span class="n">chained_coefs</span><span class="p">,</span> <span class="n">chained_vars</span><span class="p">,</span> <span class="n">chained_errorbar</span> <span class="o">=</span> <span class="n">get_results_chained_imputation</span><span class="p">(</span>
    <span class="n">Boston_X_incomplete_MCAR</span><span class="p">,</span> <span class="n">y_scaled</span>
<span class="p">)</span>
<span class="n">mice_coefs</span><span class="p">,</span> <span class="n">mice_vars</span><span class="p">,</span> <span class="n">mice_errorbar</span> <span class="o">=</span> <span class="n">get_results_mice_imputation</span><span class="p">(</span>
    <span class="n">Boston_X_incomplete_MCAR</span><span class="p">,</span> <span class="n">y_scaled</span>
<span class="p">)</span>
<span class="n">mice_y_coefs</span><span class="p">,</span> <span class="n">mice_y_vars</span><span class="p">,</span> <span class="n">mice_y_errorbar</span> <span class="o">=</span> <span class="n">get_results_mice_imputation_includingy</span><span class="p">(</span>
    <span class="n">Boston_X_incomplete_MCAR</span><span class="p">,</span> <span class="n">y_scaled</span>
<span class="p">)</span>

<span class="c1"># Combine the results from the four imputation procedures.</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="p">(</span><span class="n">full_coefs</span><span class="p">,</span> <span class="n">chained_coefs</span><span class="p">,</span> <span class="n">mice_coefs</span><span class="p">,</span> <span class="n">mice_y_coefs</span><span class="p">)</span>
<span class="nb">vars</span> <span class="o">=</span> <span class="p">(</span><span class="n">full_vars</span><span class="p">,</span> <span class="n">chained_vars</span><span class="p">,</span> <span class="n">mice_vars</span><span class="p">,</span> <span class="n">mice_y_vars</span><span class="p">)</span>
<span class="n">errorbars</span> <span class="o">=</span> <span class="p">(</span><span class="n">full_errorbar</span><span class="p">,</span> <span class="n">chained_errorbar</span><span class="p">,</span> <span class="n">mice_errorbar</span><span class="p">,</span> <span class="n">mice_y_errorbar</span><span class="p">)</span>

<span class="c1"># And plot the results</span>
<span class="n">n_situations</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_situations</span><span class="p">)</span>
<span class="n">n_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Full Data&quot;</span><span class="p">,</span> <span class="s2">&quot;Chained Imputer&quot;</span><span class="p">,</span> <span class="s2">&quot;Mice Imputer&quot;</span><span class="p">,</span> <span class="s2">&quot;Mice Imputer with y&quot;</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;purple&quot;</span><span class="p">]</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>

<span class="n">plt1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
    <span class="n">plt1</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">coefs</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">j</span> <span class="o">*</span> <span class="p">(</span><span class="n">width</span> <span class="o">/</span> <span class="n">n_situations</span><span class="p">)),</span>
        <span class="n">coefs</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
        <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
    <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">n_labels</span><span class="p">)</span>

<span class="n">plt2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
    <span class="n">plt2</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">errorbars</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">j</span> <span class="o">*</span> <span class="p">(</span><span class="n">width</span> <span class="o">/</span> <span class="n">n_situations</span><span class="p">)),</span>
        <span class="n">errorbars</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
        <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
    <span class="p">)</span>

<span class="n">plt1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;MCAR Missingness&quot;</span><span class="p">)</span>
<span class="n">plt1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Beta Coefficients&quot;</span><span class="p">)</span>
<span class="n">plt2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Standard Errors&quot;</span><span class="p">)</span>
<span class="n">plt1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Features&quot;</span><span class="p">)</span>
<span class="n">plt2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Features&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># EXAMPLE 2. SHOW MULTIPLE IMPUTATION IN A PREDICTION CONTEXT.</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># In this example, we show how to apply multiple imputation in a train/test</span>
<span class="c1"># situation. There are two approaches to get the end result of the prediction</span>
<span class="c1"># model. In approach 1 you calculate the evaluation metric for every i in m and</span>
<span class="c1"># later average these values. In approach 2 you average the predictions of</span>
<span class="c1"># every i in m and then calculate the evaluation metric. We test both</span>
<span class="c1"># approaches.</span>
<span class="c1">#</span>
<span class="c1"># Apply the regression model on the full dataset as a way of comparison.</span>
<span class="k">def</span> <span class="nf">get_results_full_data</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
    <span class="c1"># Standardize data</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
    <span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Perform estimation and prediction</span>
    <span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_predict</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">mse_full</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mse_full</span>


<span class="c1"># Use the ChainedImputer as a single imputation procedure.</span>
<span class="k">def</span> <span class="nf">get_results_single_imputation</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
    <span class="c1"># Apply imputation</span>
    <span class="n">imputer</span> <span class="o">=</span> <span class="n">ChainedImputer</span><span class="p">(</span><span class="n">n_burn_in</span><span class="o">=</span><span class="mi">99</span><span class="p">,</span> <span class="n">n_imputations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">X_train_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">X_test_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Standardize data</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
    <span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_imputed</span><span class="p">)</span>
    <span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_imputed</span><span class="p">)</span>

    <span class="c1"># Perform estimation and prediction</span>
    <span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_predict</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">mse_single</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mse_single</span>


<span class="c1"># Now use the IterativeImputer to perform multiple imputation by looping over</span>
<span class="c1"># i in m. Approach 1: pool the mse values of the m datasets.</span>
<span class="k">def</span> <span class="nf">get_results_multiple_imputation_approach1</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">multiple_mses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="c1"># Fit the imputer for every i in im</span>
        <span class="c1"># Be aware that you fit the imputer on the train data</span>
        <span class="c1"># And apply to the test data</span>
        <span class="n">imputer</span> <span class="o">=</span> <span class="n">ChainedImputer</span><span class="p">(</span><span class="n">n_burn_in</span><span class="o">=</span><span class="mi">99</span><span class="p">,</span> <span class="n">n_imputations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
        <span class="n">X_train_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">X_test_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

        <span class="c1"># Perform the steps you wish to take before fitting the estimator</span>
        <span class="c1"># Such as standardization.</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        <span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_imputed</span><span class="p">)</span>
        <span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_imputed</span><span class="p">)</span>

        <span class="c1"># Finally fit the estimator and calculate the error metric for every i</span>
        <span class="c1"># in m. Save all error metric values.</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">y_predict</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
        <span class="n">mse_approach1</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">)</span>
        <span class="n">multiple_mses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse_approach1</span><span class="p">)</span>

    <span class="c1"># Average the error metric values over the m loops to get a final result.</span>
    <span class="n">mse_approach1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">multiple_mses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mse_approach1</span>


<span class="c1"># Approach 2: We average the predictions of the m datasets and then calculate</span>
<span class="c1"># the error metric.</span>
<span class="k">def</span> <span class="nf">get_results_multiple_imputation_approach2</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">multiple_predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="c1"># Fit the imputer for every i in m</span>
        <span class="c1"># Be aware that you fit the imputer on the train data</span>
        <span class="c1"># And apply to the test data</span>
        <span class="n">imputer</span> <span class="o">=</span> <span class="n">ChainedImputer</span><span class="p">(</span><span class="n">n_burn_in</span><span class="o">=</span><span class="mi">99</span><span class="p">,</span> <span class="n">n_imputations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
        <span class="n">X_train_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">X_test_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

        <span class="c1"># Perform the steps you wish to take before fitting the estimator</span>
        <span class="c1"># Such as standardization</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        <span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_imputed</span><span class="p">)</span>
        <span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_imputed</span><span class="p">)</span>

        <span class="c1"># Finally fit the estimator and calculate the predictions for every i</span>
        <span class="c1"># in m. Save the predictions.</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">y_predict</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
        <span class="n">multiple_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_predict</span><span class="p">)</span>

    <span class="c1"># Average the predictions over the m loops</span>
    <span class="c1"># Then calculate the error metric.</span>
    <span class="n">predictions_average</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">multiple_predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">mse_approach2</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions_average</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mse_approach2</span>


<span class="k">def</span> <span class="nf">perform_simulation</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">X_incomplete</span><span class="p">,</span> <span class="n">nsim</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">X_full</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">target</span>
    <span class="n">outcome</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Start a simulation process that executes the process nsim times.</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nsim</span><span class="p">):</span>
        <span class="c1"># First, split the data in train and test dataset.</span>
        <span class="n">train_indices</span><span class="p">,</span> <span class="n">test_indices</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">random_state</span><span class="o">=</span><span class="n">j</span>
        <span class="p">)</span>
        <span class="n">X_incomplete_train</span> <span class="o">=</span> <span class="n">X_incomplete</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
        <span class="n">X_full_train</span> <span class="o">=</span> <span class="n">X_full</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
        <span class="n">X_incomplete_test</span> <span class="o">=</span> <span class="n">X_incomplete</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>
        <span class="n">X_full_test</span> <span class="o">=</span> <span class="n">X_full</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>

        <span class="c1"># Second, perform the imputation procedures and calculation of the</span>
        <span class="c1"># error metric for every one of the four situations.</span>
        <span class="n">mse_full</span> <span class="o">=</span> <span class="n">get_results_full_data</span><span class="p">(</span><span class="n">X_full_train</span><span class="p">,</span> <span class="n">X_full_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        <span class="n">mse_single</span> <span class="o">=</span> <span class="n">get_results_single_imputation</span><span class="p">(</span>
            <span class="n">X_incomplete_train</span><span class="p">,</span> <span class="n">X_incomplete_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
        <span class="p">)</span>
        <span class="n">mse_approach1</span> <span class="o">=</span> <span class="n">get_results_multiple_imputation_approach1</span><span class="p">(</span>
            <span class="n">X_incomplete_train</span><span class="p">,</span> <span class="n">X_incomplete_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
        <span class="p">)</span>
        <span class="n">mse_approach2</span> <span class="o">=</span> <span class="n">get_results_multiple_imputation_approach2</span><span class="p">(</span>
            <span class="n">X_incomplete_train</span><span class="p">,</span> <span class="n">X_incomplete_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
        <span class="p">)</span>

        <span class="c1"># Save the outcome of every simulation round</span>
        <span class="n">outcome</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">mse_full</span><span class="p">,</span> <span class="n">mse_single</span><span class="p">,</span> <span class="n">mse_approach1</span><span class="p">,</span> <span class="n">mse_approach2</span><span class="p">))</span>

    <span class="c1"># Return the mean and standard deviation of the nsim outcome values</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="c1"># Execute the simulation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Executing Example 2 MCAR Missingness...&quot;</span><span class="p">)</span>

<span class="c1"># Generate missing values with a MCAR mechanism</span>
<span class="n">am_MCAR</span> <span class="o">=</span> <span class="n">MultivariateAmputation</span><span class="p">(</span><span class="n">mechanisms</span><span class="o">=</span><span class="s2">&quot;MCAR&quot;</span><span class="p">)</span>
<span class="n">Boston_X_incomplete_MCAR</span> <span class="o">=</span> <span class="n">am_MCAR</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>

<span class="c1"># Perform the simulation</span>
<span class="n">mse_means</span><span class="p">,</span> <span class="n">mse_std</span> <span class="o">=</span> <span class="n">perform_simulation</span><span class="p">(</span><span class="n">load_boston</span><span class="p">(),</span> <span class="n">Boston_X_incomplete_MCAR</span><span class="p">,</span> <span class="n">nsim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Plot results</span>
<span class="n">n_situations</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_situations</span><span class="p">)</span>
<span class="n">n_labels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Full Data&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Single Imputation&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MI Average MSE&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MI Average Predictions&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="s2">&quot;yellow&quot;</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span>
        <span class="n">j</span><span class="p">,</span> <span class="n">mse_means</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">xerr</span><span class="o">=</span><span class="n">mse_std</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span>
    <span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;MCAR Missingness&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Mean Squared Error&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">n_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.088 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-multiple-imputation-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/bc363b373646ff530bef73deec5c8b84/plot_multiple_imputation.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_multiple_imputation.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/e403bbef57515c8faf05c8b2a835aa1d/plot_multiple_imputation.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_multiple_imputation.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Rianne Schouten, Davina Zamanzadeh, &amp; Prabhant Singh.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>