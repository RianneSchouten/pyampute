{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Evaluating missing values with grid search and a pipeline\n\nGenerating missing values in a complete dataset (we call this `amputation`) seems like a bizarre thing to do. However, most people who work with all sorts of data will acknowledge that missing data is widespread and can be a severe issue for various types of analyses and models. In order to understand the effect of missing values and to know which missing data methods are appropriate in which situation, we perform simulation studies. And for that, we need amputation. \n\nWith package ``pyampute``, we provide the multivariate amputation methodology proposed by `Schouten et al. (2018)`_. Because our :class:`~pyampute.ampute.MultivariateAmputation` class follows scikit-learn's ``fit`` and ``transform`` paradigm, it is straightforward to design a missing data experiment. \n\nHere, we demonstrate how that works.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Rianne Schouten <https://rianneschouten.github.io/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General experimental setup\n\n In general, evaluating the effect of missing values is done in four steps:\n\n 1. Generate or import a complete dataset\n 2. Ampute the dataset\n 3. Impute the dataset\n 4. Compare the performance of a model between the datasets in step 1, 2 and 3.\n\n It is often wise to first inspect the effect of amputation (by comparing the datasets in steps 1 and 2) before comparing with step 3. Let's get started.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete dataset\n\n A simulation starts with a complete dataset. Make sure that you use a dataset where variables are correlated with each other; otherwise it will not make sense to use a sophisticated amputation algorithm (see `Schouten et al. (2021)`_ for a discussion on this topic).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nm = 5\nn = 1000\n\nmean = np.repeat(5, m)\ncor = 0.5\ncov = np.identity(m)\ncov[cov == 0] = cor\nrng = np.random.default_rng()\ncompl_dataset = rng.multivariate_normal(mean, cov, n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multivariate amputation\n\n Vary the parameters of the amputation procedure. Read the `documentation`_ or `this blogpost`_ to understand how you can tune the parameters such that you create varying types of missingness.\n\n As an example, here, we generate `one` missing data pattern with missing values in the `first two variables`: ``\"incomplete_vars\":[0,1]``. We vary the proportion of incomplete rows between 0.1 and 0.9.\n\n We furthermore experiment with the three mechanisms: Missing Completely At Random (MCAR), Missing At Random (MAR) and Missing Not At Random (MNAR) (cf. `Rubin (1976)`_).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameters = {\n    \"amputation__prop\": [0.1, 0.5, 0.9],\n    \"amputation__patterns\": [\n        [{\"incomplete_vars\": [0, 1], \"mechanism\": \"MCAR\"}],\n        [{\"incomplete_vars\": [0, 1], \"mechanism\": \"MAR\"}],\n        [{\"incomplete_vars\": [0, 1], \"mechanism\": \"MNAR\"}],\n    ],\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing data methods\n\n `SimpleImputer`_ is a univariate, single imputation method that is commonly used. However, in case of MCAR missingness, it distorts the relation with other variables, and in case of MAR and MNAR missingness it will not resolve issues with shifted variable distributions (see `Van Buuren (2018)`_). It may be better to use a method such as `IterativeImputer`_.\n\n Yet, to demonstrate the working of a simulation pipeline, we will work with SimpleImputer for now.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameters[\"imputation__strategy\"] = [\"mean\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n\n How you wish to evaluate the amputation and imputation greatly depends on the goal of your model. We will first show the experiment for a LinearRegression estimator, using predictors and an outcome feature.\n\n We recommend to read `A custom pipeline with more possibilities`_ to see how custom ``BaseEstimator``'s and ``TransformerMixin``'s can be used to gain a deeper understanding of the impact of missing values.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom pyampute.ampute import MultivariateAmputation\n\nsteps = [\n    (\"amputation\", MultivariateAmputation()),\n    (\"imputation\", SimpleImputer()),\n    (\"estimator\", LinearRegression()),\n]\npipe = Pipeline(steps)\ngrid = GridSearchCV(\n    estimator=pipe, param_grid=parameters, scoring=make_scorer(mean_squared_error),\n)\n\nX, y = compl_dataset[:, :-1], compl_dataset[:, -1]\nX_compl_train, X_compl_test, y_compl_train, y_compl_test = train_test_split(\n    X, y, random_state=2022\n)\n\ngrid.fit(X_compl_train, y_compl_train)\ngrid.score(X_compl_test, y_compl_test)\nresults = pd.DataFrame(grid.cv_results_)\n\nres = results[\n    [\n        \"param_amputation__patterns\",\n        \"param_amputation__prop\",\n        \"param_imputation__strategy\",\n        \"mean_test_score\",\n    ]\n]\nres.columns = [\"mechanism\", \"prop\", \"imputation\", \"score\"]\nres"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}